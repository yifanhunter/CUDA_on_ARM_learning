{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2f0b982",
   "metadata": {},
   "source": [
    "# CUDA编程模型---错误检测，事件及存储单元"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85f8e24",
   "metadata": {},
   "source": [
    "#### 通过之前的学习，我们已经初步掌握了利用GPU加速应用程序的方法。接下来，我们针对更多细节加以训练。本次实验课将会介绍：  \n",
    "1. Cuda编程模型中的错误检测\n",
    "2. Cuda编程模型中的事件\n",
    "3. Cuda编程模型中多种类型的存储单元\n",
    "4. 利用共享存储单元来加速矩阵乘法\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437ab24d",
   "metadata": {},
   "source": [
    "#### 1.Cuda编程模型中的错误检测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53a8520",
   "metadata": {},
   "source": [
    "可以查看Cuda error的四个函数：  \n",
    "```C++\n",
    "__host__​__device__​const char* \tcudaGetErrorName ( cudaError_t error )\n",
    "Returns the string representation of an error code enum name.  \n",
    "\n",
    "__host__​__device__​const char* \tcudaGetErrorString ( cudaError_t error )\n",
    "Returns the description string for an error code.  \n",
    "\n",
    "__host__​__device__​cudaError_t \tcudaGetLastError ( void )\n",
    "Returns the last error from a runtime call.  \n",
    "\n",
    "__host__​__device__​cudaError_t \tcudaPeekAtLastError ( void )\n",
    "Returns the last error from a runtime call.  \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0e986f",
   "metadata": {},
   "source": [
    "这里我们采用第二个，并将其封装在error.cuh文件中：\n",
    "```C++\n",
    "#pragma once\n",
    "#include <stdio.h>\n",
    "\n",
    "#define CHECK(call)                                   \\\n",
    "do                                                    \\\n",
    "{                                                     \\\n",
    "    const cudaError_t error_code = call;              \\\n",
    "    if (error_code != cudaSuccess)                    \\\n",
    "    {                                                 \\\n",
    "        printf(\"CUDA Error:\\n\");                      \\\n",
    "        printf(\"    File:       %s\\n\", __FILE__);     \\\n",
    "        printf(\"    Line:       %d\\n\", __LINE__);     \\\n",
    "        printf(\"    Error code: %d\\n\", error_code);   \\\n",
    "        printf(\"    Error text: %s\\n\",                \\\n",
    "            cudaGetErrorString(error_code));          \\\n",
    "        exit(1);                                      \\\n",
    "    }                                                 \\\n",
    "} while (0)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0390d5a",
   "metadata": {},
   "source": [
    "那么我们就可以在代码中这么使用：\n",
    "```C++\n",
    "    CHECK(cudaMemcpy(d_b, h_b, sizeof(int)*n*k, cudaMemcpyHostToDevice));\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a434200b",
   "metadata": {},
   "source": [
    "接下来，大家在之前做的[matrix_mul.cu](matrix_mul.cu)文件，添加CHECK()，如果遇到麻烦，请参考[result1.cu](result1.cu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deeb3cb0",
   "metadata": {},
   "source": [
    "修改Makefile文件，编译程序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3da9a55b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/cuda/bin/nvcc -arch=compute_80 -code=sm_80  matrix_mul.cu -o ./matrix_mul\n"
     ]
    }
   ],
   "source": [
    "!make"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d72731",
   "metadata": {},
   "source": [
    "执行查看效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "daf2b181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass!!!\n"
     ]
    }
   ],
   "source": [
    "!./matrix_mul"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f2c213",
   "metadata": {},
   "source": [
    "修改\n",
    "```C++\n",
    "CHECK(cudaMemcpy(h_c, d_c, (sizeof(int)*m*k), cudaMemcpyDeviceToHost)); \n",
    "```\n",
    "成\n",
    "```C++\n",
    "CHECK(cudaMemcpy(h_c, d_c, (sizeof(int)*m*k*2), cudaMemcpyDeviceToHost));\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c6afcd",
   "metadata": {},
   "source": [
    "再编译一下，并执行查看结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c0681c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/cuda/bin/nvcc -arch=compute_80 -code=sm_80  matrix_mul.cu -o ./matrix_mul\n"
     ]
    }
   ],
   "source": [
    "!make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b23955dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Error:\n",
      "    File:       matrix_mul.cu\n",
      "    Line:       81\n",
      "    Error code: 1\n",
      "    Error text: invalid argument\n"
     ]
    }
   ],
   "source": [
    "!./matrix_mul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cab1fe82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The --print-api-trace  switch is ignored by nsys.\n",
      "WARNING: matrix_mul and any of its children processes will be profiled.\n",
      "\n",
      "CUDA Error:\n",
      "    File:       matrix_mul.cu\n",
      "    Line:       81\n",
      "    Error code: 1\n",
      "    Error text: invalid argument\n",
      "Generating '/tmp/nsys-report-1d0b.qdstrm'\n",
      "[1/7] [========================100%] report1.nsys-rep\n",
      "[2/7] [========================100%] report1.sqlite\n",
      "[3/7] Executing 'nvtxsum' stats report\n",
      "SKIPPED: /mnt/CUDA_on_ARM/03_3.4/report1.sqlite does not contain NV Tools Extension (NVTX) data.\n",
      "[4/7] Executing 'cudaapisum' stats report\n",
      "\n",
      "CUDA API Statistics:\n",
      "\n",
      " Time (%)  Total Time (ns)  Num Calls   Avg (ns)   Med (ns)  Min (ns)  Max (ns)   StdDev (ns)        Name      \n",
      " --------  ---------------  ---------  ----------  --------  --------  ---------  -----------  ----------------\n",
      "     99.8        201094896          4  50273724.0    5515.5      4133  201079732  100537338.7  cudaMallocHost  \n",
      "      0.1           207006          3     69002.0    3972.0      3217     199817     113289.7  cudaMalloc      \n",
      "      0.0            77393          4     19348.3   17164.5       711      42353      17223.5  cudaMemcpy      \n",
      "      0.0            27889          1     27889.0   27889.0     27889      27889          0.0  cudaLaunchKernel\n",
      "\n",
      "[5/7] Executing 'gpukernsum' stats report\n",
      "\n",
      "CUDA Kernel Statistics:\n",
      "\n",
      " Time (%)  Total Time (ns)  Instances  Avg (ns)  Med (ns)  Min (ns)  Max (ns)  StdDev (ns)                         Name                        \n",
      " --------  ---------------  ---------  --------  --------  --------  --------  -----------  ---------------------------------------------------\n",
      "    100.0             6240          1    6240.0    6240.0      6240      6240          0.0  gpu_matrix_mult(int *, int *, int *, int, int, int)\n",
      "\n",
      "[6/7] Executing 'gpumemtimesum' stats report\n",
      "\n",
      "CUDA Memory Operation Statistics (by time):\n",
      "\n",
      " Time (%)  Total Time (ns)  Count  Avg (ns)  Med (ns)  Min (ns)  Max (ns)  StdDev (ns)      Operation     \n",
      " --------  ---------------  -----  --------  --------  --------  --------  -----------  ------------------\n",
      "     74.5            11968      2    5984.0    5984.0      5600      6368        543.1  [CUDA memcpy HtoD]\n",
      "     25.5             4096      1    4096.0    4096.0      4096      4096          0.0  [CUDA memcpy DtoH]\n",
      "\n",
      "[7/7] Executing 'gpumemsizesum' stats report\n",
      "\n",
      "CUDA Memory Operation Statistics (by size):\n",
      "\n",
      " Total (MB)  Count  Avg (MB)  Med (MB)  Min (MB)  Max (MB)  StdDev (MB)      Operation     \n",
      " ----------  -----  --------  --------  --------  --------  -----------  ------------------\n",
      "      0.080      2     0.040     0.040     0.040     0.040        0.000  [CUDA memcpy HtoD]\n",
      "      0.040      1     0.040     0.040     0.040     0.040        0.000  [CUDA memcpy DtoH]\n",
      "\n",
      "Generated:\n",
      "    /mnt/CUDA_on_ARM/03_3.4/report1.nsys-rep\n",
      "    /mnt/CUDA_on_ARM/03_3.4/report1.sqlite\n"
     ]
    }
   ],
   "source": [
    "# !sudo /usr/local/cuda/bin/nvprof ./matrix_mul\n",
    "!/usr/local/cuda/bin/nsys nvprof --print-api-trace  ./matrix_mul"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3819b0e9",
   "metadata": {},
   "source": [
    "这时我们就精准的定位了出现错误的文件，位置，以及错误原因"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2069fe14",
   "metadata": {},
   "source": [
    "#### 2. Cuda编程模型中的事件。事件的本质就是一个标记，它与其所在的流内的特定点相关联。可以使用时间来执行以下两个基本任务：\n",
    "- 同步流执行\n",
    "- 监控设备的进展"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240ecef4",
   "metadata": {},
   "source": [
    "流中的任意点都可以通过API插入事件以及查询事件完成的函数，只有事件所在流中其之前的操作都完成后才能触发事件完成。默认流中设置事件，那么其前面的所有操作都完成时，事件才出发完成。\n",
    "事件就像一个个路标，其本身不执行什么功能，就像我们最原始测试c语言程序的时候插入的无数多个printf一样。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6bd14e",
   "metadata": {},
   "source": [
    "创建和销毁： \n",
    "\n",
    "声明:\n",
    "```C++\n",
    "cudaEvent_t event;\n",
    "```\n",
    "创建：\n",
    "```C++\n",
    "cudaError_t cudaEventCreate(cudaEvent_t* event);\n",
    "```\n",
    "销毁：\n",
    "```C++\n",
    "cudaError_t cudaEventDestroy(cudaEvent_t event);\n",
    "```\n",
    "添加事件到当前执行流：\n",
    "```C++\n",
    "cudaError_t cudaEventRecord(cudaEvent_t event, cudaStream_t stream = 0);\n",
    "```\n",
    "等待事件完成，设立flag：\n",
    "```C++\n",
    "cudaError_t cudaEventSynchronize(cudaEvent_t event);//阻塞\n",
    "cudaError_t cudaEventQuery(cudaEvent_t event);//非阻塞\n",
    "```\n",
    "当然，我们也可以用它来记录执行的事件：\n",
    "```C++\n",
    "cudaError_t cudaEventElapsedTime(float* ms, cudaEvent_t start, cudaEvent_t stop);\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf724ad6",
   "metadata": {},
   "source": [
    "接下来，我们就修改matrix_mul.cu程序，来测试一下核函数执行的时间，如果遇到麻烦，请参考[result2.cu](result2.cu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465d912e",
   "metadata": {},
   "source": [
    "编译并执行程序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b99e62cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/cuda/bin/nvcc -arch=compute_80 -code=sm_80  matrix_mul.cu -o ./matrix_mul\n"
     ]
    }
   ],
   "source": [
    "!make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "14086033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time = 0.023232 ms.\n",
      "Pass!!!\n"
     ]
    }
   ],
   "source": [
    "!./matrix_mul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6609f3c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======== Warning: nvprof is not supported on devices with compute capability 8.0 and higher.\n",
      "                  Use NVIDIA Nsight Systems for GPU tracing and CPU sampling and NVIDIA Nsight Compute for GPU profiling.\n",
      "                  Refer https://developer.nvidia.com/tools-overview for more details.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#! /usr/local/cuda/bin/nvprof ./matrix_mul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51c77db0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unknown command: --print-api-trace\n",
      " usage: nsys [--version] [--help] <command> [<args>] [application] [<application args>]\n",
      "\n",
      " The most commonly used nsys commands are:\n",
      "\tprofile       Run an application and capture its profile into a QDSTRM file.\n",
      "\tlaunch        Launch an application ready to be profiled.\n",
      "\tstart         Start a profiling session.\n",
      "\tstop          Stop a profiling session and capture its profile into a QDSTRM file.\n",
      "\tcancel        Cancel a profiling session and discard any collected data.\n",
      "\tstats         Generate statistics from an existing nsys-rep or SQLite file.\n",
      "\tstatus        Provide current status of CLI or the collection environment.\n",
      "\tshutdown      Disconnect launched processes from the profiler and shutdown the profiler.\n",
      "\tsessions list List active sessions.\n",
      "\texport        Export nsys-rep file into another format.\n",
      "\tanalyze       Run rules on an existing nsys-rep or SQLITE file.\n",
      "\tnvprof        Translate nvprof switches to nsys switches and execute collection.\n",
      "\n",
      " Use 'nsys --help <command>' for more information about a specific command.\n",
      "\n",
      " To run a basic profiling session:   nsys profile ./my-application\n",
      " For more details see \"Profiling from the CLI\" at https://docs.nvidia.com/nsight-systems\n"
     ]
    }
   ],
   "source": [
    "# 这里根据自己的环境进行了修改。\n",
    "!/usr/local/cuda/bin/nsys --print-api-trace ./matrix_mul"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcfe9c7d",
   "metadata": {},
   "source": [
    "#### 3.Cuda编程模型中的多种存储单元"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1984119",
   "metadata": {},
   "source": [
    "![gpu_memory](gpu_memory.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0b6b07",
   "metadata": {},
   "source": [
    "- 寄存器\n",
    "\n",
    "寄存器是速度最快的存储单元，位于GPU芯片的SM上，用于存储局部变量。每个SM（SMX）上有成千上万的32位寄存器，当kernel函数启动后，这些寄存器被分配给指定的线程来使用。由于不同kernel函数需要的寄存器数量也不相等，所以，也有一个规定一个线程的最大寄存器数量是256个。寄存器的最小单位是register file，所以，在很多图上也会用register file来表示。\n",
    "\n",
    "- Local Memory\n",
    "\n",
    "Local Memory本身在硬件中没有特定的存储单元，而是从Global Memory虚拟出来的地址空间。Local Memory是为寄存器无法满足存储需求的情况而设计的，主要是用于存放单线程的大型数组和变量。Local Memory是线程私有的，线程之间是不可见的。由于GPU硬件单位没有Local Memory的存储单元，所以，针对它的访问是比较慢的。从上面的表格中，也可以看到跟Global Memory的访问速度是接近的。\n",
    "\n",
    "- Shared Memory\n",
    "\n",
    "Shared Memory位于GPU芯片上，访问延迟仅次于寄存器。Shared Memory是可以被一个Block中的所有Thread来进行访问的，可以实现Block内的线程间的低开销通信。在SMX中，L1 Cache跟Shared Memory是共享一个64KB的告诉存储单元的，他们之间的大小划分不同的GPU结构不太一样；\n",
    "\n",
    "- Constant Memory\n",
    "\n",
    "Constant Memory类似于Local Memory，也是没有特定的存储单元的，只是Global Memory的虚拟地址。因为它是只读的，所以简化了缓存管理，硬件无需管理复杂的回写策略。Constant Memory启动的条件是同一个warp所有的线程同时访问同样的常量数据。\n",
    "\n",
    "- Global Memory\n",
    "\n",
    "Global Memory在某种意义上等同于GPU显存，kernel函数通过Global Memory来读写显存。Global Memory是kernel函数输入数据和写入结果的唯一来源。\n",
    "\n",
    "- Texture Memory\n",
    "\n",
    "Texture Memory是GPU的重要特性之一，也是GPU编程优化的关键。Texture Memory实际上也是Global Memory的一部分，但是它有自己专用的只读cache。这个cache在浮点运算很有用，Texture Memory是针对2D空间局部性的优化策略，所以thread要获取2D数据就可以使用texture Memory来达到很高的性能。从读取性能的角度跟Constant Memory类似。\n",
    "\n",
    "- Host Memory\n",
    "\n",
    "主机端存储器主要是内存可以分为两类：可分页内存（Pageable）和页面 （Page-Locked 或 Pinned）内存。\n",
    "\n",
    "可分页内存通过操作系统 API(malloc/free) 分配存储器空间，该内存是可以换页的，即内存页可以被置换到磁盘中。可分页内存是不可用使用DMA（Direct Memory Acess)来进行访问的，普通的C程序使用的内存就是这个内存。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66719cfb",
   "metadata": {},
   "source": [
    "#### 4.利用Shrared Memory来优化矩阵乘法"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69e5460",
   "metadata": {},
   "source": [
    "![shared_memory](shared_memory.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80d431e",
   "metadata": {},
   "source": [
    "当我们在处理矩阵乘法时，假设矩阵M(m,k)\\*N(k,n) = P(m,n)。那么，矩阵M中的一个数值m(x,y),就要被grid中所有满足threadIdx.y+blockIdx.y\\*blockDim.y = y的线程从Global Memory中读一次，一共就是K次。那么，我们看到这么多重复读取，就可以把这个变量放在Shared Memory中，极大地减少每次的读取时间。我们可以按照下面的代码来修改martix_mul的核函数："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d213f6a",
   "metadata": {},
   "source": [
    "```C++   \n",
    "__global__ void gpu_matrix_mult_shared(int *d_a, int *d_b, int *d_result, int m, int n, int k) \n",
    "{\n",
    "    __shared__ int tile_a[BLOCK_SIZE][BLOCK_SIZE];\n",
    "    __shared__ int tile_b[BLOCK_SIZE][BLOCK_SIZE];\n",
    "\n",
    "    int row = blockIdx.y * BLOCK_SIZE + threadIdx.y;\n",
    "    int col = blockIdx.x * BLOCK_SIZE + threadIdx.x;\n",
    "    int tmp = 0;\n",
    "    int idx;\n",
    "\n",
    "    for (int sub = 0; sub < gridDim.x; ++sub) \n",
    "    {\n",
    "        idx = row * n + sub * BLOCK_SIZE + threadIdx.x;\n",
    "        tile_a[threadIdx.y][threadIdx.x] = row<n && (sub * BLOCK_SIZE + threadIdx.x)<n? d_a[idx]:0;\n",
    "        idx = (sub * BLOCK_SIZE + threadIdx.y) * n + col;\n",
    "        tile_b[threadIdx.y][threadIdx.x] = col<n && (sub * BLOCK_SIZE + threadIdx.y)<n? d_b[idx]:0;\n",
    "        \n",
    "        __syncthreads();\n",
    "        for (int k = 0; k < BLOCK_SIZE; ++k) \n",
    "        {\n",
    "            tmp += tile_a[threadIdx.y][k] * tile_b[k][threadIdx.x];\n",
    "        }\n",
    "        __syncthreads();\n",
    "    }\n",
    "    if(row < n && col < n)\n",
    "    {\n",
    "        d_result[row * n + col] = tmp;\n",
    "    }\n",
    "}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0392ae00",
   "metadata": {},
   "source": [
    "![array_2d](array_2to1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d40305d",
   "metadata": {},
   "source": [
    "修改[matrix_mul.cu](matrix_mul.cu)文件，利用Makefile编译，并执行。如果遇到困难，请参考[result4.cu](result4.cu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b4962187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/cuda/bin/nvcc -arch=compute_80 -code=sm_80  matrix_mul.cu -o ./matrix_mul\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "!make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "add6fb0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time_global = 0.056512 ms.\n",
      "Time_share = 0.02192 ms.\n",
      "Pass!!!\n"
     ]
    }
   ],
   "source": [
    "!./matrix_mul"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d0a148",
   "metadata": {},
   "source": [
    "利用nvprof来查看性能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c261efa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!sudo /usr/local/cuda/bin/nvprof ./matrix_mul"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bee9b50",
   "metadata": {},
   "source": [
    "课后作业： \n",
    "\n",
    "1. 修改BLOCK_SIZE查看性能变化\n",
    "2. 修改代码，尝试产生bank_conflict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "690f6780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/cuda/bin/nvcc -arch=compute_80 -code=sm_80  matrix_mul.cu -o ./matrix_mul\n",
      "Time_global = 9.65494 ms.\n",
      "Time_share = 22.9141 ms.\n",
      "Pass!!!\n"
     ]
    }
   ],
   "source": [
    "# BLOCK_SIZE = 2\n",
    "!make\n",
    "!./matrix_mul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "59188e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/cuda/bin/nvcc -arch=compute_80 -code=sm_80  matrix_mul.cu -o ./matrix_mul\n",
      "Time_global = 3.7712 ms.\n",
      "Time_share = 4.26186 ms.\n",
      "Pass!!!\n"
     ]
    }
   ],
   "source": [
    "# BLOCK_SIZE = 4\n",
    "!make\n",
    "!./matrix_mul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "02961bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/cuda/bin/nvcc -arch=compute_80 -code=sm_80  matrix_mul.cu -o ./matrix_mul\n",
      "Time_global = 2.06074 ms.\n",
      "Time_share = 1.33578 ms.\n",
      "Pass!!!\n"
     ]
    }
   ],
   "source": [
    "# BLOCK_SIZE = 8\n",
    "!make\n",
    "!./matrix_mul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b549cc6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/cuda/bin/nvcc -arch=compute_80 -code=sm_80  matrix_mul.cu -o ./matrix_mul\n",
      "Time_global = 2.34336 ms.\n",
      "Time_share = 1.63059 ms.\n",
      "Pass!!!\n"
     ]
    }
   ],
   "source": [
    "# BLOCK_SIZE = 10\n",
    "!make\n",
    "!./matrix_mul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "542e0186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/cuda/bin/nvcc -arch=compute_80 -code=sm_80  matrix_mul.cu -o ./matrix_mul\n",
      "Time_global = 2.07722 ms.\n",
      "Time_share = 1.15958 ms.\n",
      "258892266 \n",
      "Pass!!!\n"
     ]
    }
   ],
   "source": [
    "# BLOCK_SIZE = 16\n",
    "!make\n",
    "!./matrix_mul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c71f809",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/cuda/bin/nvcc -arch=compute_80 -code=sm_80  matrix_mul.cu -o ./matrix_mul\n",
      "Time_global = 2.10771 ms.\n",
      "Time_share = 1.1791 ms.\n",
      "258892266 \n",
      "Pass!!!\n"
     ]
    }
   ],
   "source": [
    "# BLOCK_SIZE = 20\n",
    "!make\n",
    "!./matrix_mul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19b85587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/cuda/bin/nvcc -arch=compute_80 -code=sm_80  matrix_mul.cu -o ./matrix_mul\n",
      "Time_global = 2.09245 ms.\n",
      "Time_share = 1.26205 ms.\n",
      "258892266 \n",
      "Pass!!!\n"
     ]
    }
   ],
   "source": [
    "# BLOCK_SIZE = 32\n",
    "!make\n",
    "!./matrix_mul"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3948121f",
   "metadata": {},
   "source": [
    "课后作业： \n",
    "2. 修改代码，尝试产生bank_conflict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b215ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64359cb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6728e0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a094391f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef576a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60f168e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d070610",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b985f5d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
