{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8138de8a",
   "metadata": {},
   "source": [
    "# CUDA编程模型--- 执行流 和 运行库"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f8a22b",
   "metadata": {},
   "source": [
    "#### 1.CUDA流\n",
    "CUDA程序的并行层次主要有两个，一个是核函数内部的并行，一个是核函数的外部的并行。我们之前讨论的都是核函数的内部的并行。核函数外部的并行主要指：\n",
    "- 核函数计算与数据传输之间的并行\n",
    "- 主机计算与数据传输之间的并行\n",
    "- 不同的数据传输之间的并行\n",
    "- 核函数计算与主机计算之间的并行\n",
    "- 不同核函数之间的并行\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b11a8bf",
   "metadata": {},
   "source": [
    "CUDA流表示一个GPU操作队列，该队列中的操作将以添加到流中的先后顺序而依次执行。我们的所有CUDA操作都是在流中进行的，虽然我们可能没发现，但是有我们前面的例子中的指令，内核启动，都是在CUDA流中进行的，只是这种操作是隐式的，所以肯定还有显式的，所以，流分为：\n",
    "- 隐式声明的流，我们叫做空流\n",
    "- 显式声明的流，我们叫做非空流"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116c9df2",
   "metadata": {},
   "source": [
    "基于流的异步内核启动和数据传输支持以下类型的粗粒度并发：\n",
    "- 重叠主机和设备计算\n",
    "- 重叠主机计算和主机设备数据传输\n",
    "- 重叠主机设备数据传输和设备计算\n",
    "- 并发设备计算（多个设备）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc98cc2",
   "metadata": {},
   "source": [
    "接下来，我们就完成下面这个核函数，在两个流并发的实现：\n",
    "```C++\n",
    "__global__ void kernel( int *a, int *b, int *c ) {\n",
    "    int idx = threadIdx.x + blockIdx.x * blockDim.x;\n",
    "    if (idx < N) {\n",
    "        int idx1 = (idx + 1) % 256;\n",
    "        int idx2 = (idx + 2) % 256;\n",
    "        float   as = (a[idx] + a[idx1] + a[idx2]) / 3.0f;\n",
    "        float   bs = (b[idx] + b[idx1] + b[idx2]) / 3.0f;\n",
    "        c[idx] = (as + bs) / 2;\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f3b62b",
   "metadata": {},
   "source": [
    "创建[stream.cu](stream.cu)文件，详情请参考[result1.cu](result1-stream.cu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63606a90",
   "metadata": {},
   "source": [
    "修改Makefile，利用Makefile编译，并执行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24b3f5b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/cuda/bin/nvcc  -arch=compute_80 -code=sm_80 stream.cu -o ./stream\n"
     ]
    }
   ],
   "source": [
    "!make -f Makefile_stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fdf7ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken:  17.8 ms\n"
     ]
    }
   ],
   "source": [
    "!./stream"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d83401",
   "metadata": {},
   "source": [
    "利用nvprof测试程序性能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d848a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The --print-api-trace  switch is ignored by nsys.\n",
      "WARNING: stream and any of its children processes will be profiled.\n",
      "\n",
      "Time taken:  16.0 ms\n",
      "Generating '/tmp/nsys-report-18d8.qdstrm'\n",
      "[1/7] [========================100%] report2.nsys-rep\n",
      "[2/7] [========================100%] report2.sqlite\n",
      "[3/7] Executing 'nvtxsum' stats report\n",
      "SKIPPED: /mnt/CUDA_on_ARM/04_4.2/report2.sqlite does not contain NV Tools Extension (NVTX) data.\n",
      "[4/7] Executing 'cudaapisum' stats report\n",
      "\n",
      "CUDA API Statistics:\n",
      "\n",
      " Time (%)  Total Time (ns)  Num Calls   Avg (ns)     Med (ns)    Min (ns)  Max (ns)   StdDev (ns)          Name         \n",
      " --------  ---------------  ---------  -----------  -----------  --------  ---------  -----------  ---------------------\n",
      "     56.8        210899907          2  105449953.5  105449953.5      1126  210898781  149127162.0  cudaEventCreate      \n",
      "     27.1        100507050          3   33502350.0   32961255.0  32765564   34780231    1110994.4  cudaHostAlloc        \n",
      "     11.1         41349375          3   13783125.0   13563678.0  13306769   14478928     616122.5  cudaFreeHost         \n",
      "      4.2         15639781          2    7819890.5    7819890.5    666736   14973045   10116088.1  cudaStreamSynchronize\n",
      "      0.3          1184700          6     197450.0     177177.5    176067     298035      49296.4  cudaFree             \n",
      "      0.3          1177719          6     196286.5     166180.5    161734     350390      75577.1  cudaMalloc           \n",
      "      0.1           269473         60       4491.2       3173.0      2616      41165       5561.8  cudaMemcpyAsync      \n",
      "      0.0           141840         20       7092.0       4263.0      3630      51847      10679.2  cudaLaunchKernel     \n",
      "      0.0            41462          2      20731.0      20731.0      4479      36983      22983.8  cudaEventRecord      \n",
      "      0.0            16350          2       8175.0       8175.0      3787      12563       6205.6  cudaStreamDestroy    \n",
      "      0.0            15750          2       7875.0       7875.0      1940      13810       8393.4  cudaStreamCreate     \n",
      "      0.0             5949          1       5949.0       5949.0      5949       5949          0.0  cudaEventSynchronize \n",
      "\n",
      "[5/7] Executing 'gpukernsum' stats report\n",
      "\n",
      "CUDA Kernel Statistics:\n",
      "\n",
      " Time (%)  Total Time (ns)  Instances  Avg (ns)  Med (ns)  Min (ns)  Max (ns)  StdDev (ns)             Name            \n",
      " --------  ---------------  ---------  --------  --------  --------  --------  -----------  ---------------------------\n",
      "    100.0           586021         20   29301.1   29456.0     25280     31327       1217.8  kernel(int *, int *, int *)\n",
      "\n",
      "[6/7] Executing 'gpumemtimesum' stats report\n",
      "\n",
      "CUDA Memory Operation Statistics (by time):\n",
      "\n",
      " Time (%)  Total Time (ns)  Count  Avg (ns)  Med (ns)  Min (ns)  Max (ns)  StdDev (ns)      Operation     \n",
      " --------  ---------------  -----  --------  --------  --------  --------  -----------  ------------------\n",
      "     67.4         15430531     40  385763.3  383618.0    349570    428579      20493.9  [CUDA memcpy HtoD]\n",
      "     32.6          7454222     20  372711.1  375250.5    321186    377218      12164.7  [CUDA memcpy DtoH]\n",
      "\n",
      "[7/7] Executing 'gpumemsizesum' stats report\n",
      "\n",
      "CUDA Memory Operation Statistics (by size):\n",
      "\n",
      " Total (MB)  Count  Avg (MB)  Med (MB)  Min (MB)  Max (MB)  StdDev (MB)      Operation     \n",
      " ----------  -----  --------  --------  --------  --------  -----------  ------------------\n",
      "    167.772     40     4.194     4.194     4.194     4.194        0.000  [CUDA memcpy HtoD]\n",
      "     83.886     20     4.194     4.194     4.194     4.194        0.000  [CUDA memcpy DtoH]\n",
      "\n",
      "Generated:\n",
      "    /mnt/CUDA_on_ARM/04_4.2/report2.nsys-rep\n",
      "    /mnt/CUDA_on_ARM/04_4.2/report2.sqlite\n"
     ]
    }
   ],
   "source": [
    "# !sudo /usr/local/cuda/bin/nvprof ./stream\n",
    "\n",
    "!/usr/local/cuda/bin/nsys nvprof --print-api-trace  ./stream"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c22491",
   "metadata": {},
   "source": [
    "编辑[stream2.cu](stream2.cu) 删除其中一个流，并测试性能，如果遇到麻烦，请参考[result2.cu](result2.cu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790609f4",
   "metadata": {},
   "source": [
    "利用Makefile文件编译，并执行程序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f5fa4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/cuda/bin/nvcc  -arch=compute_80 -code=sm_80 stream2.cu -o ./stream2\n",
      "\u001b[01m\u001b[0m\u001b[01mstream2.cu(34)\u001b[0m: \u001b[01;35mwarning\u001b[0m #177-D: variable \u001b[01m\"stream1\"\u001b[0m was declared but never referenced\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!make -f Makefile_stream2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf68d44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc37b90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken:  29.7 ms\n"
     ]
    }
   ],
   "source": [
    "!./stream2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963f4009",
   "metadata": {},
   "source": [
    "#### 2.cuBLAS  \n",
    "cuBLAS 库是基于 NVIDIA®CUDA™ 运行时的 BLAS（基本线性代数子程序）的实现。它允许用户访问 NVIDIA GPU 的计算资源。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9834b423",
   "metadata": {},
   "source": [
    "在[cublas_gemm.cu](cublas_gemm.cu)中使用```cublasDgemm()```函数，如果遇到麻烦，请参考[result3.cu](result3.cu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d65945",
   "metadata": {},
   "source": [
    "修改Makefile文件，这里需要将```$(CC)  $(TEST_SOURCE) -o  $(TARGETBIN)``` 修改为```$(CC)  $(TEST_SOURCE) -lcublas -o  $(TARGETBIN)```  \n",
    "\n",
    "编译，并执行程序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7d45a670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/cuda/bin/nvcc  -arch=compute_80 -code=sm_80  cublas_gemm.cu -lcublas -o  ./cublas_gemm\n"
     ]
    }
   ],
   "source": [
    "!make -f Makefile_cublas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e97da288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A = \n",
      "  0.000000  2.000000  4.000000\n",
      "  1.000000  3.000000  5.000000\n",
      "B = \n",
      "  0.000000  3.000000\n",
      "  1.000000  4.000000\n",
      "  2.000000  5.000000\n",
      "C = A x B = \n",
      " 10.000000 28.000000\n",
      " 13.000000 40.000000\n"
     ]
    }
   ],
   "source": [
    "!./cublas_gemm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90790b48",
   "metadata": {},
   "source": [
    "利用nvprof查看程序性能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2413b26e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The --print-api-trace  switch is ignored by nsys.\n",
      "WARNING: cublas_gemm and any of its children processes will be profiled.\n",
      "\n",
      "A = \n",
      "  0.000000  2.000000  4.000000\n",
      "  1.000000  3.000000  5.000000\n",
      "B = \n",
      "  0.000000  3.000000\n",
      "  1.000000  4.000000\n",
      "  2.000000  5.000000\n",
      "C = A x B = \n",
      " 10.000000 28.000000\n",
      " 13.000000 40.000000\n",
      "Generating '/tmp/nsys-report-56e0.qdstrm'\n",
      "[1/7] [========================100%] report3.nsys-rep\n",
      "[2/7] [========================100%] report3.sqlite\n",
      "[3/7] Executing 'nvtxsum' stats report\n",
      "SKIPPED: /mnt/CUDA_on_ARM/04_4.2/report3.sqlite does not contain NV Tools Extension (NVTX) data.\n",
      "[4/7] Executing 'cudaapisum' stats report\n",
      "\n",
      "CUDA API Statistics:\n",
      "\n",
      " Time (%)  Total Time (ns)  Num Calls   Avg (ns)    Med (ns)  Min (ns)   Max (ns)   StdDev (ns)            Name          \n",
      " --------  ---------------  ---------  -----------  --------  --------  ----------  -----------  ------------------------\n",
      "     69.6       1074339890          8  134292486.3   15847.5      1552  1073851749  379639284.2  cudaFree                \n",
      "     16.3        251425458          4   62856364.5   21014.5      6063   251377366  125680668.2  cudaMemcpy              \n",
      "     14.0        216483346          6   36080557.7   38592.0      4904   216017168   88150695.6  cudaMalloc              \n",
      "      0.0           180165        754        238.9     188.0       130        1051        132.0  cuGetProcAddress        \n",
      "      0.0            50822          1      50822.0   50822.0     50822       50822          0.0  cudaLaunchKernel        \n",
      "      0.0            16583          4       4145.8    1600.0      1012       12371       5501.5  cudaDeviceSynchronize   \n",
      "      0.0            12419         18        689.9     413.5       390        5218       1130.6  cudaEventDestroy        \n",
      "      0.0            11516         18        639.8     490.5       427        2480        489.7  cudaEventCreateWithFlags\n",
      "      0.0             4471          2       2235.5    2235.5      1916        2555        451.8  cuInit                  \n",
      "\n",
      "[5/7] Executing 'gpukernsum' stats report\n",
      "\n",
      "CUDA Kernel Statistics:\n",
      "\n",
      " Time (%)  Total Time (ns)  Instances  Avg (ns)  Med (ns)  Min (ns)  Max (ns)  StdDev (ns)                                         Name                                        \n",
      " --------  ---------------  ---------  --------  --------  --------  --------  -----------  -----------------------------------------------------------------------------------\n",
      "    100.0            11616          1   11616.0   11616.0     11616     11616          0.0  void cutlass::Kernel<cutlass_80_tensorop_d884gemm_32x32_16x5_nn_align1>(T1::Params)\n",
      "\n",
      "[6/7] Executing 'gpumemtimesum' stats report\n",
      "\n",
      "CUDA Memory Operation Statistics (by time):\n",
      "\n",
      " Time (%)  Total Time (ns)  Count  Avg (ns)  Med (ns)  Min (ns)  Max (ns)  StdDev (ns)      Operation     \n",
      " --------  ---------------  -----  --------  --------  --------  --------  -----------  ------------------\n",
      "     62.1             4192      3    1397.3    1184.0      1152      1856        397.5  [CUDA memcpy HtoD]\n",
      "     37.9             2560      1    2560.0    2560.0      2560      2560          0.0  [CUDA memcpy DtoH]\n",
      "\n",
      "[7/7] Executing 'gpumemsizesum' stats report\n",
      "\n",
      "CUDA Memory Operation Statistics (by size):\n",
      "\n",
      " Total (MB)  Count  Avg (MB)  Med (MB)  Min (MB)  Max (MB)  StdDev (MB)      Operation     \n",
      " ----------  -----  --------  --------  --------  --------  -----------  ------------------\n",
      "      0.000      3     0.000     0.000     0.000     0.000        0.000  [CUDA memcpy HtoD]\n",
      "      0.000      1     0.000     0.000     0.000     0.000        0.000  [CUDA memcpy DtoH]\n",
      "\n",
      "Generated:\n",
      "    /mnt/CUDA_on_ARM/04_4.2/report3.nsys-rep\n",
      "    /mnt/CUDA_on_ARM/04_4.2/report3.sqlite\n"
     ]
    }
   ],
   "source": [
    "# !sudo /usr/local/cuda/bin/nvprof ./cublas_gemm\n",
    "!/usr/local/cuda/bin/nsys nvprof --print-api-trace  ./cublas_gemm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f51bea7",
   "metadata": {},
   "source": [
    "课后作业：\n",
    "1. 尝试调用cublas做矩阵乘法和向量加法操作，跟之前自己写的程序对比，查看性能差距，并分析可能改进的地方？\n",
    "2. 如果本地文件存储着2个1000000*1000000的矩阵，我们想将这两个矩阵进行乘积，如何操作？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c43a8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
