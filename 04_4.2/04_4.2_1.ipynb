{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fff1da2",
   "metadata": {},
   "source": [
    "# CUDA编程模型---基于ARM平台的Jetson NANO存储单元调用"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbe5ecd",
   "metadata": {},
   "source": [
    "Jetson系列（包括TX1，TX2，Xavier，NANO等）用的都是SoC芯片，CPU和GPU集成在一个芯片上，自然用的是同一个内存，因此GPU可以直接访问内存上的数据（100多GB/s）而不用受到PCIE的限制（10多GB/s)。\n",
    "\n",
    "因此，在CUDA编程中可以舍弃cudaMemcpy系列函数（相当于在同一个内存上徒劳地复制了一遍），转而使用zero copy或者统一内存unified memory\n",
    "今天的课程将介绍，在NANO上使用Pinned Memory加速程序"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a97e76",
   "metadata": {},
   "source": [
    "CUDA应用程序可以使用各种类型的内存缓冲区，例如设备内存，可分页的主机内存，固定内存和统一内存. 即使将这些内存缓冲区类型分配在同一物理设备上，每种类型也具有不同的访问和缓存行为，如下图所示. 选择最合适的内存缓冲区类型对于有效执行应用程序很重要.\n",
    "![memory_type](memory_type.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bc3d17",
   "metadata": {},
   "source": [
    "先使用老的编译下 ，[matrix_mul_old.cu](matrix_mul_old.cu)文件， \n",
    "如果遇到麻烦，请参考[result_old.cu](result_old.cu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29e4a4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/cuda/bin/nvcc  -arch=compute_80 -code=sm_80 matrix_mul_old.cu -o ./matrix_mul_old\n"
     ]
    }
   ],
   "source": [
    "!make -f Makefile_mlu_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0a0d481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Time = 1.34502 ms.\n",
      "CPU Time = 3846.52 ms.\n",
      "Pass!!!\n"
     ]
    }
   ],
   "source": [
    "!./matrix_mul_old"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70eaab2",
   "metadata": {},
   "source": [
    "接下来，我们就修改[matrix_mul.cu](matrix_mul.cu)文件，去掉```cudaMalloc()``` 和 ```cudaMemcpy()```，而采用统一内存的方法。  \n",
    "如果遇到麻烦，请参考[result1.cu](result1.cu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6aaee8",
   "metadata": {},
   "source": [
    "编译，并执行程序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ef04673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/cuda/bin/nvcc  -arch=compute_80 -code=sm_80 matrix_mul.cu -o ./matrix_mul\n"
     ]
    }
   ],
   "source": [
    "!make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d96ef75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Time = 2.75894 ms.\n",
      "CPU Time = 3889.41 ms.\n",
      "Pass!!!\n"
     ]
    }
   ],
   "source": [
    "!./matrix_mul"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5b5663",
   "metadata": {},
   "source": [
    "利用nvprof查看性能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66bbbaaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The --print-api-trace  switch is ignored by nsys.\n",
      "WARNING: matrix_mul and any of its children processes will be profiled.\n",
      "\n",
      "GPU Time = 3.69034 ms.\n",
      "CPU Time = 3960.84 ms.\n",
      "Pass!!!\n",
      "Generating '/tmp/nsys-report-bc6c.qdstrm'\n",
      "[1/7] [========================100%] report1.nsys-rep\n",
      "[2/7] [========================100%] report1.sqlite\n",
      "[3/7] Executing 'nvtxsum' stats report\n",
      "SKIPPED: /mnt/CUDA_on_ARM/04_4.2/report1.sqlite does not contain NV Tools Extension (NVTX) data.\n",
      "[4/7] Executing 'cudaapisum' stats report\n",
      "\n",
      "CUDA API Statistics:\n",
      "\n",
      " Time (%)  Total Time (ns)  Num Calls   Avg (ns)   Med (ns)   Min (ns)  Max (ns)   StdDev (ns)          Name        \n",
      " --------  ---------------  ---------  ----------  ---------  --------  ---------  -----------  --------------------\n",
      "     98.3        238638994          3  79546331.3     1110.0       841  238637043  137776597.8  cudaEventCreate     \n",
      "      1.6          3896582          2   1948291.0  1948291.0    123378    3773204    2580816.7  cudaEventSynchronize\n",
      "      0.1           163450          3     54483.3    22503.0      3144     137803      72803.3  cudaEventRecord     \n",
      "      0.0            28643          1     28643.0    28643.0     28643      28643          0.0  cudaLaunchKernel    \n",
      "      0.0            11956          3      3985.3      462.0       435      11059       6126.0  cudaEventDestroy    \n",
      "      0.0             4325          1      4325.0     4325.0      4325       4325          0.0  cudaEventQuery      \n",
      "\n",
      "[5/7] Executing 'gpukernsum' stats report\n",
      "\n",
      "CUDA Kernel Statistics:\n",
      "\n",
      " Time (%)  Total Time (ns)  Instances  Avg (ns)   Med (ns)   Min (ns)  Max (ns)  StdDev (ns)                             Name                           \n",
      " --------  ---------------  ---------  ---------  ---------  --------  --------  -----------  ----------------------------------------------------------\n",
      "    100.0          3685354          1  3685354.0  3685354.0   3685354   3685354          0.0  gpu_matrix_mult_shared(int *, int *, int *, int, int, int)\n",
      "\n",
      "[6/7] Executing 'gpumemtimesum' stats report\n",
      "\n",
      "CUDA Memory Operation Statistics (by time):\n",
      "\n",
      " Time (%)  Total Time (ns)  Count  Avg (ns)  Med (ns)  Min (ns)  Max (ns)  StdDev (ns)              Operation            \n",
      " --------  ---------------  -----  --------  --------  --------  --------  -----------  ---------------------------------\n",
      "     71.7          2092636    144   14532.2    5999.5      1631     81760      21324.5  [CUDA Unified Memory memcpy DtoH]\n",
      "     28.3           826066     70   11800.9    4799.0      2399     85152      18517.3  [CUDA Unified Memory memcpy HtoD]\n",
      "\n",
      "[7/7] Executing 'gpumemsizesum' stats report\n",
      "\n",
      "CUDA Memory Operation Statistics (by size):\n",
      "\n",
      " Total (MB)  Count  Avg (MB)  Med (MB)  Min (MB)  Max (MB)  StdDev (MB)              Operation            \n",
      " ----------  -----  --------  --------  --------  --------  -----------  ---------------------------------\n",
      "     24.011    144     0.167     0.033     0.004     1.044        0.280  [CUDA Unified Memory memcpy DtoH]\n",
      "      8.004     70     0.114     0.023     0.004     1.012        0.226  [CUDA Unified Memory memcpy HtoD]\n",
      "\n",
      "Generated:\n",
      "    /mnt/CUDA_on_ARM/04_4.2/report1.nsys-rep\n",
      "    /mnt/CUDA_on_ARM/04_4.2/report1.sqlite\n"
     ]
    }
   ],
   "source": [
    "#!sudo /usr/local/cuda/bin/nvprof ./matrix_mul\n",
    "\n",
    "!/usr/local/cuda/bin/nsys nvprof --print-api-trace  ./matrix_mul"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a242059",
   "metadata": {},
   "source": [
    "这时，我们和上一节课的发现程序执行快了很多，并且数据传输的部分 [CUDA memcpy HtoD]  和  [CUDA memcpy DtoH] 不见了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cadf97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f79aa9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ad038b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08d80c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66eae659",
   "metadata": {},
   "source": [
    "课后作业：\n",
    "- 尝试利用统一内存和shared memory完成矩阵转置操作"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3c100e",
   "metadata": {},
   "source": [
    "#https://zhuanlan.zhihu.com/p/450242129\n",
    "\n",
    "#这里是用非统一内存写法，同意内存可以类比修改"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bd06c6",
   "metadata": {},
   "source": [
    "先使用老的编译下 ，[matrix_mul_transpose.cu](matrix_mul_transpose.cu)文件，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d0859a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6a9f1a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/cuda/bin/nvcc  -arch=compute_80 -code=sm_80 matrix_mul_transpose.cu -o ./matrix_mul_transpose\n",
      "pass\n",
      "GPU time is : 0.346400 \n"
     ]
    }
   ],
   "source": [
    "!make -f Makefile_mlu_transpose\n",
    "!./matrix_mul_transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b5723fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make: 'matrix_mul_transpose' is up to date.\n",
      "pass\n",
      "GPU time is : 0.378720 \n"
     ]
    }
   ],
   "source": [
    "!make -f Makefile_mlu_transpose\n",
    "!./matrix_mul_transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70b157a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60056c3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
